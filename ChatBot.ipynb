{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd3745ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import torch\n",
    "from model import NeuralNet\n",
    "from nltk_utils import bag_of_words, tokenize\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef944ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3afcaef7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m     intents \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      4\u001b[0m FILE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m input_size \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      8\u001b[0m hidden_size \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.pth'"
     ]
    }
   ],
   "source": [
    "with open('intents.json', 'r') as f:\n",
    "    intents = json.load(f)\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data[\"all_words\"]\n",
    "tags = data[\"tags\"]\n",
    "model_state = data[\"model_sdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')tate\"]\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "\n",
    "bot_name = \"DialogueX\"\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97e0167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! I'm here to help you with any questions you have about our college. How can I be of service? Type 'quit' to exit\n",
      "You: hey\n",
      "DialogueX: Hi there! How can I help you?\n",
      "You: Who are you\n",
      "DialogueX: I didn't understand...\n",
      "You: What do you understand\n",
      "DialogueX: Bachelor of Engineering - (Aerospace Engg.) - Lateral Entry - 3 Years - 117000/- INR\n",
      "\n",
      "You: What was that?\n",
      "DialogueX: I didn't understand...\n",
      "You: TF are you\n",
      "DialogueX: I didn't understand...\n",
      "You: DIeee\n",
      "DialogueX: I didn't understand...\n",
      "You: HUMAN\n",
      "DialogueX: I didn't understand...\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "def bot_speaking(message):\n",
    "    print(f\"{bot_name}: {message}\")\n",
    "    engine.say(message)\n",
    "    engine.runAndWait()\n",
    "    if engine._inLoop:\n",
    "        engine.endLoop()\n",
    "\n",
    "\n",
    "print(\"Hi there! I'm here to help you with any questions you have about our college. How can I be of service? Type 'quit' to exit\")\n",
    "\n",
    "while True:\n",
    "    sentence = input('You: ')\n",
    "    if sentence == 'quit':\n",
    "        break\n",
    "\n",
    "    sentence = tokenize(sentence)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X)\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents[\"intents\"]:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                bot_response = random.choice(intent['responses'])\n",
    "                bot_speaking(bot_response)\n",
    "    else:\n",
    "        bot_response = \"I didn't understand...\"\n",
    "        bot_speaking(bot_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56677b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! I'm here to help you with any questions you have about our college. How can I be of service? Type 'quit' to exit\n",
      "You: hey\n",
      "DialogueX: Hey! What can I do for you?\n",
      "You: How can I know my grades?\n",
      "DialogueX: I didn't understand...\n",
      "You: I want to know the marking pattern\n",
      "DialogueX: Here are the subjects along with their subject codes, type, and credits: 1. Design and Analysis of Algorithms with Lab (21CSH-311) - Theory & Practical, 5 credits. 2. Operating Systems (21CST-313) - Theory, 3 credits. 3. Advance Programming Lab-1 (21CSP-314) - Practical, 2 credits. 4. SOFT COMPUTING (Professional Elective-I) (21CST-332) - Theory & Practical, 2 credits. 5. STATISTICAL INFERENCE USING R (Professional Elective-I) (21CST-331) - Theory & Practical, 2 credits. 6. Aptitude (21TDY-302) - Practical, 2 credits. 7. Project-II (21CSR-318) - Practical, 1 credit. 8. Industrial Summer Training (21CSX-322) - Practical, 4 credits. 9. Soft Skills (21TDY-301) - Practical, 2 credits. 10. Fundamentals of Image Processing (21CSY-313) - Theory, 3 credits. For more information, you can refer to the college's official website or course catalog at 'https://www.cuchd.in/'\n"
     ]
    }
   ],
   "source": [
    "def bot_speaking(message):\n",
    "    print(f\"{bot_name}: {message}\")\n",
    "    engine.say(message)\n",
    "    engine.runAndWait()\n",
    "    if engine._inLoop:\n",
    "        engine.endLoop()\n",
    "\n",
    "\n",
    "print(\"Hi there! I'm here to help you with any questions you have about our college. How can I be of service? Type 'quit' to exit\")\n",
    "\n",
    "while True:\n",
    "    sentence = input('You: ')\n",
    "    if sentence == 'quit':\n",
    "        break\n",
    "\n",
    "    sentence = tokenize(sentence)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X)\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents[\"intents\"]:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                bot_response = random.choice(intent['responses'])\n",
    "                bot_speaking(bot_response)\n",
    "    else:\n",
    "        bot_response = \"I didn't understand...\"\n",
    "        bot_speaking(bot_response)\n",
    "        \n",
    "        \n",
    "user_input = widgets.Text(description=\"You:\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_user_input_change(change):\n",
    "    user_message = change['new']\n",
    "    if len(user_message) > 0:\n",
    "        bot_response = get_bot_response(user_message)\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            display(widgets.HTML(f\"<b>{bot_name}:</b> {bot_response}\"))\n",
    "            bot_speaking(bot_response)\n",
    "\n",
    "user_input.observe(on_user_input_change, names='value')\n",
    "\n",
    "# Display the UI\n",
    "display(user_input, output_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff50e0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
